{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# sklearn version: 1.1.2\n",
    "# python version: 3.8.9\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import sklearn.neighbors._base\n",
    "sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "from missingpy import MissForest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Columns (10,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,828,829,843,844,847,848,854,855,856,857,858,871) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "# import student, school, teacher data\n",
    "stu_data = pd.read_csv('E:\\\\EIE-Storage\\\\E1003 Onedrive HKU\\\\OneDrive - The University Of Hong Kong\\\\EIA-Research\\\\2023-04 SEL_ML_HLM_PISA2018\\\\Phillipines\\\\Stu.csv')\n",
    "sch_data = pd.read_csv('E:\\\\EIE-Storage\\\\E1003 Onedrive HKU\\\\OneDrive - The University Of Hong Kong\\\\EIA-Research\\\\2023-04 SEL_ML_HLM_PISA2018\\\\Phillipines\\\\\\Sch.csv')\n",
    "tch_data = pd.read_csv('E:\\\\EIE-Storage\\\\E1003 Onedrive HKU\\\\OneDrive - The University Of Hong Kong\\\\EIA-Research\\\\2023-04 SEL_ML_HLM_PISA2018\\\\Phillipines\\\\Tch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select variables\n",
    "stu_var = ['CNTRYID','CNTSCHID','CNTSTUID',\n",
    "           'ST215Q01HA','ST215Q02HA',\n",
    "           'ST216Q01HA','ST216Q02HA','ST216Q03HA','ST216Q04HA',\n",
    "           'ST185Q01HA','ST185Q02HA','ST185Q03HA',\n",
    "           'ST215Q03HA','ST215Q04HA','ST215Q05HA',\n",
    "           'ST216Q05HA','ST216Q06HA',\n",
    "           'EMOSUPS','CURSUPP','SOCONPA','TEACHSUP','PERFEED','ADAPTIVITY','DIRINS','STIMREAD',\n",
    "           'DISCLIMA','BELONG','BEINGBULLIED','PERCOMP','PERCOOP','ATTLNACT','PASCHPOL','DISCRIM',\n",
    "           'ESCS','JOYREADP','HISEI','PAREDINT','HOMEPOS','ST001D01T','ST004D01T','AGE']\n",
    "sch_var = ['CNTRYID','CNTSCHID','CREACTIV','EDUSHORT']\n",
    "tch_var = ['CNTRYID','CNTSCHID','CNTTCHID','TCOTLCOMP','SATJOB']\n",
    "stu_select_data = stu_data[stu_var]\n",
    "sch_select_data = sch_data[sch_var]\n",
    "tch_select_data = tch_data[tch_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Delete missing code\n",
    "missing_code1 = [95,97,98,99,995, 997, 998, 999,'95','97','98','99','995','997','998','999']\n",
    "missing_code2 = [5,7,8,9,'5','7','8','9']\n",
    "\n",
    "stu_select_data.replace(' ', np.nan, inplace=True)\n",
    "stu_select_data.replace(missing_code1, np.nan, inplace=True)\n",
    "stu_select_data[['ST185Q01HA','ST185Q02HA','ST185Q03HA']].replace(missing_code2, np.nan, inplace=True)\n",
    "\n",
    "sch_select_data.replace(' ',np.nan, inplace=True)\n",
    "sch_select_data.replace(missing_code1, np.nan, inplace=True)\n",
    "sch_select_data['CREACTIV'].replace(missing_code2, np.nan, inplace=True)\n",
    "\n",
    "tch_select_data.replace(' ',np.nan, inplace=True)\n",
    "tch_select_data.replace(missing_code1, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mix table \n",
    "# Tch & Sch \n",
    "tch_data_group = tch_select_data.groupby('CNTSCHID').mean()\n",
    "tch_data_group2 = tch_data_group.reset_index()\n",
    "sch_tch = pd.merge(sch_select_data,tch_data_group2, left_on ='CNTSCHID',right_on='CNTSCHID') #按照某个column名称进行拼接(concat拼接，merge和Join按照某个字段对两个表格进行结合)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch_tch.drop(columns = ['CNTRYID_x','CNTRYID_y'],inplace=True)\n",
    "\n",
    "# stu & sch\n",
    "stu_tch_sch = pd.merge(stu_select_data,sch_tch, left_on ='CNTSCHID',right_on='CNTSCHID') #按照某个column名称进行拼接(concat拼接，merge和Join按照某个字段对两个表格进行结合)\n",
    "\n",
    "stu_tch_sch.drop(columns = 'CNTTCHID',inplace=True)\n",
    "\n",
    "new_data = stu_tch_sch\n",
    "\n",
    "new_data.to_csv('1-before imputation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3077483078.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    stu_data[Responsible decision-making] = ST215Q01HA+ST215Q02HA\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#aggregate social and emtional skiils\n",
    "stu_data['Responsible decision-making'] = 'ST215Q01HA' + 'ST215Q02HA'\n",
    "stu_data['Self-management']  = 'ST216Q01HA' + 'ST216Q02HA' + 'ST216Q03HA' + 'ST216Q04HA'\n",
    "stu_data['Self-awareness'] = 'ST185Q01HA' + 'ST185Q02HA' + 'ST185Q03HA'\n",
    "stu_data['Social awareness'] = 'ST215Q03HA' + 'ST215Q04HA' + 'ST215Q05HA'\n",
    "stu_data['Relationship skills'] = 'ST216Q05HA' + 'ST216Q06HA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing value\n",
    "imputer = MissForest() # we don't use other f\n",
    "data_impute = pd.DataFrame(imputer.fit_transform(new_data))\n",
    "column = new_data.columns\n",
    "data_impute.columns = column\n",
    "\n",
    "# Build the model --> what model we want to cho\n",
    "data_impute.to_csv('2-data_impute.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
